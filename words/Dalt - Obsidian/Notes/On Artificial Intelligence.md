This is a table of contents covering my process to understand AI, AI alignment, the Turing Test, and subsequent vocabulary words, ideas, and thesis' that impact the development of Artificial Intelligence. I'd like to begin my writing down all questions I have and then will start the research process.

**A simple definition of AI is: the study of creating intelligence in algorithms**

## Questions
- **The Turing test seems to be more of a philosophical idea rather than an actual rigorous test or formula. Is that true, or am I just ignorant?**
- **What does the term "AI Alignment" actually mean? I've seen it used in a variety of contexts and would like to understand it better.**
	- AI Alignment: The aim to align AI goal systems with human values. The [[AI Alignment Problem]] is a thought experiment that is some sort of problem where a poorly designed AI machine seizes control and won't let the creator make modifications after it has launched. Cleary this is bad.
- **What is AGI and how does that differ from just AI?**
- **LessWrong seems to be infatuated with AI - does everyone on there just want to make sure AI is used effectively and efficient and safely? Or is there some bigger question they're all hoping to solve?**
	- From the AI page: 
		 > On LessWrong, the primary focus of AI discussion is to ensure that as humanity builds increasingly powerful AI systems, the outcome will be good. The central concern is that a powerful enough AI, if not designed and implemented with sufficient understanding, would optimize something unintended by its creators and pose an existential threat to the future of humanity. This is known as the _AI alignment_ problem.

## Links
- This seems like the best overall place to start and will work as a good launchpad.
	- https://www.lesswrong.com/tag/ai
	- ![[Screen Shot 2022-07-02 at 11.55.30 AM.png]]

## Basic Alignment Theory
- [[AIXI]]
- [[Coherent Extrapolated Volition]]
- [[Complexity of Value]]



[[Orthogonality Thesis]]
[[AI vs AGI]]
