Status: #ðŸŒ±
Tags: #ai 
***
# The central question of AI research seems to find out if computers can do something they haven't explicitly been told what to do

As I'm getting started on my research to understand the problems and goals with AI systems and AI research, the main question to answer seems to be: **Can computers do something they haven't explicitly been told to do by their creators?**

That could be way off, but I think that's a good ELI5 version of the point of AI.

If a computer just knows 100 Wikipedia pages really well and is averaging the knowledge of everything on there, then it isn't really artificial intelligence, it's just a really good computerâ€“and the ideal human brain. But maybe that's what AI is supposed to be: a really good human brain.

But it seems a lot of people in AI communities assume a good version of AI can do something that humans can't do.

It also can't be just figuring puzzles out. For an AI to be truly intelligent, it has to invent something, right?

