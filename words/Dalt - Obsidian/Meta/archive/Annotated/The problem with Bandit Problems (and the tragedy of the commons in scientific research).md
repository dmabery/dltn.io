From here: https://www.kevinzollman.com/uploads/5/0/3/6/50361245/conservativismv16.pdf

Bandit problems capture an important aspect of many real-world learning problems where there is a trade-off between exploiting the action which appears best (based on the payoffs that one has observed) and exploring other options. For example, if a researcher was interested in developing a more effective treatment for peptic ulcer disease, the evidence available from 1954 until at least the mid 1980’s suggested that the best course of action would be to focus on improving acid suppression either through surgery, drugs, or lifestyle and diet changes. Each member of that scientific community individually chose to pursue the option that seemed best, the excess acid hypothesis, and left experimenting with the bacterial hypothesis to others. As a result, the entirety of scientific research on the topic was focused on acid suppression, and essentially no exploration of the bacterial hypothesis occurred. Only after two relatively unknown scientists explored a wild idea was it discovered that the bacterial hypothesis was correct. In this particular historical setting scientists were exploring too little and exploiting too much (cf. Zollman, 2010).

Suppose that, unbeknownst to Exploiter, she is confronted by two arms, one of which always pays $1 and the other pays $0 half the time and $3 the other half (making the second arm superior). For simplicity, assume that she starts by pulling each arm once, so that she has a single data point to begin estimating the expected payoff of each arm. With a 0.5 probability, Exploiter received $0 when she pulled the second arm and so will choose the first arm (which is suboptimal) for the remainder of her pulls. Even if she received $3 from the second arm on the first pull, she might switch if the second arm’s average payoff drops below $1. Once she switches to the sub-optimal arm, she will never switch back. Now consider Explorer. Explorer will alternate between choosing arm one and arm two throughout his trials. By the end of the trials, Explorer will have the best estimate of the value of the two arms, but he will have failed to take advantage of the information. Suppose that he is unknowingly confronted by a relatively easy two arm bandit. One arm pays $1 on every pull, the other pays $0 on every pull. Explorer will pull the second arm half the time, and thus receive an average payoff of $0.50. One might be able to do better by learning over time to avoid the second arm. Exploiter does badly because she does not investigate sufficiently so that she can determine which is the best arm, while Explorer does badly because he does not use the information he collects. Thought of as big choices in scientific investigation, Exploiter has abandoned a superior scientific theory too quickly because it had an early failure. (This is essentially what happened to the scientific community studying peptic ulcer disease.) Explorer continued to apply an inferior theory, e.g. geocentric models of the solar system, long after it was shown to be inferior to another theory. Neither extreme is desirable; the optimal strategy will involve a combination of exploring and exploiting.