---
Author: [[@GiadaPistilli on Twitter]]
Title: I Will No Longer Engage...
Link: https://twitter.com/GiadaPistilli/status/1530136739959951361
Date: 2024-07-06
---
T - I Will No Longer Engage...

1
- I will no longer engage in philosophical discussions about conscious AI/superintelligent machines, and here's why. (longðŸ§µ1/11) ([View Tweet](https://twitter.com/GiadaPistilli/status/1530136739959951361))
2
    - Note: Save
1
- I have been studying AI ethics and the philosophy of technology since 2017. At the very beginning, I also used to think that the problem of superintelligent machines was an urgent issue to address philosophically. (2/11) ([View Tweet](https://twitter.com/GiadaPistilli/status/1530136741436444673))
1
- People used to quote Hawking and talk about human replacement. People were (and still are) pretty scared about those predictions and want philosophers to think about human existence in the AI era. (3/11) ([View Tweet](https://twitter.com/GiadaPistilli/status/1530136742925303808))
1
- When I started to work in an AI company and dug those technical questions, I understood there were lots of misunderstandings, fantasies, and fakeries around AI. (4/11) ([View Tweet](https://twitter.com/GiadaPistilli/status/1530136744175316992))
1
- I rationalized my arguments and directed them to specific and existing problems (to name a few: acceptability and adaptability of AI, underrepresentation of minority cultures and languages, treatment of humans behind the AI curtain). (5/11) ([View Tweet](https://twitter.com/GiadaPistilli/status/1530136745907462144))
1
- Yet it was and still is difficult to find literature in philosophy dealing with these questions. And at every conference I attend, I find myself clarifying the technical aspects on which I apply ethics without getting valuable feedback on my approach. (6/11) ([View Tweet](https://twitter.com/GiadaPistilli/status/1530136747623030784))
1
- I feel alone and misunderstood in my own field, philosophy. For example, I was told today that talking about pressing problems in AI technologies while leaving out the issue of superintelligent machines is negligent and irresponsible. (7/11) ([View Tweet](https://twitter.com/GiadaPistilli/status/1530136749350985728))
1
- Not only does this way of thinking hurt the philosophical field, but focusing on these sci-fi issues only perpetuates the collective panic that exists around these technologies while neglecting their actual risks. (8/11) ([View Tweet](https://twitter.com/GiadaPistilli/status/1530136751049691136))
1
- No, I do not feel negligent or irresponsible. On the contrary, I find it negligent and irresponsible not to encourage philosophical studies in AI on empirical research and alongside AI practitioners. (9/11) ([View Tweet](https://twitter.com/GiadaPistilli/status/1530136752828174338))
1
- Because in the meantime, AI systems exist, are pervasive, and pose countless ethical and social justice questions. Philosophers, do interdisciplinary research and help your colleagues find specific issues on which to focus. (10/11) ([View Tweet](https://twitter.com/GiadaPistilli/status/1530136754493308928))
1
- And above all: if you feel an urgency to discuss matters concerning conscious AI/superintelligent machines, do not contact me. Thank you. (11/11) ([View Tweet](https://twitter.com/GiadaPistilli/status/1530136756217053184))
